{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tkr\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "GR = (1+np.sqrt(5))/2 # aspect ratio for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_points_T(npts, dim=2, dof=10, std=False):\n",
    "    '''\n",
    "    If X = Z/\\sqrt{G} where Z ~ N(0,I_m) and G ~ Gamma(nu/2,2/nu) then X ~ IST(m,nu)\n",
    "    '''\n",
    "    \n",
    "    # set mean vector and covariance matrix\n",
    "    mvec = [0]*dim\n",
    "    cmtx = np.identity(dim)\n",
    "    \n",
    "    # create normal vectors\n",
    "    zpts = np.random.multivariate_normal(mvec, cmtx, npts)\n",
    "    \n",
    "    # create gamma values\n",
    "    gvals = np.tile(np.random.gamma(dof/2.0, 2.0/dof, npts),(dim,1)).T\n",
    "    \n",
    "    # create points\n",
    "    points = zpts/np.sqrt(gvals)\n",
    "    \n",
    "    # standardise if required\n",
    "    if std:\n",
    "        sf = dof/(dof-2) \n",
    "        points = points/np.sqrt(sf)\n",
    "    \n",
    "    return(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_points_GG(npts, dim=2, expo=2, std=True):\n",
    "    '''\n",
    "    If X = UR where U is uniformly distributed on the unit sphere in R^m \n",
    "    and R = V^{1/s} where V ~ Gamma(m/s,2) then X ~ GG(m,s). From (Solaro 2004).\n",
    "    '''\n",
    "    \n",
    "    # set mean vector and covariance matrix\n",
    "    mvec = [0]*dim\n",
    "    cmtx = np.identity(dim)\n",
    "    \n",
    "    # create isotropic normal vectors\n",
    "    zpts = st.multivariate_normal.rvs(mvec, cmtx, npts)\n",
    "    \n",
    "    # project onto sphere\n",
    "    upts = np.array([z/np.linalg.norm(z) for z in zpts])\n",
    "    \n",
    "    # create gamma values\n",
    "    gvals = st.gamma.rvs(dim/expo, scale=2, size=npts)**(1/expo)\n",
    "    \n",
    "    # create points\n",
    "    points = np.multiply(upts, gvals[:, np.newaxis]) if dim > 1 else np.reshape(np.multiply(upts, gvals),(npts,1))\n",
    "    \n",
    "    # standardise if required\n",
    "    if std:\n",
    "        sf = (2**(2/expo))*sc.special.gamma((dim+2)/expo)/(dim*sc.special.gamma(dim/expo))\n",
    "        points = points/np.sqrt(sf)\n",
    "    \n",
    "    return points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_constant(dim=2, expo=2):\n",
    "    \n",
    "    return (expo*np.e/dim)**(dim/expo)*np.pi**(dim/2)*sc.special.gamma(dim/expo+1)/sc.special.gamma(dim/2+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sample_moment(points, expo):\n",
    "    \n",
    "    # Euclidean norms\n",
    "    norms = np.sqrt(np.sum(points**2, axis=1)) \n",
    "    \n",
    "    # power-weighted norms\n",
    "    pw_norms = norms**expo \n",
    "    \n",
    "    # value\n",
    "    return np.mean(pw_norms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_near_neighbour_distances(points, nnmax):\n",
    "    \n",
    "    # search tree\n",
    "    tree = KDTree(points)\n",
    "    \n",
    "    # extract distances\n",
    "    dist, ind = tree.query(points, k=nnmax+1)\n",
    "    \n",
    "    # exclude zeroth neighbour (the point itself)\n",
    "    return dist[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy_estimates(points, nnmax=1):\n",
    "\n",
    "    # dimensions \n",
    "    npts, dim = points.shape\n",
    "\n",
    "    # volume of unit ball \n",
    "    vub = (np.pi**(dim/2))/(sc.special.gamma(dim/2 + 1))\n",
    "    \n",
    "    # digamma function values (scipy.special.digamma is slow)\n",
    "    psi = -np.euler_gamma + np.array([0] + [1/i for i in range(1,nnmax)]).cumsum()\n",
    "    \n",
    "    # near neighbour distances\n",
    "    nnd = compute_near_neighbour_distances(points, nnmax)\n",
    "\n",
    "    # geometric means\n",
    "    gmeans = sc.stats.mstats.gmean(nnd)\n",
    "\n",
    "    # value\n",
    "    return m*np.log(gmeans) + np.log(vub) + np.log(npts-1) - psi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(points, expo=2, nnmax=1):\n",
    "    \n",
    "    # dimensions \n",
    "    npts, dim = points.shape\n",
    "\n",
    "    # entropy estimates\n",
    "    eest = compute_entropy_estimates(points, nnmax)\n",
    "\n",
    "    # moment estimate\n",
    "    smom = compute_sample_moment(points, expo)\n",
    "   \n",
    "    # constant\n",
    "    const = compute_constant(dim, expo)\n",
    "\n",
    "    # value\n",
    "    return eest - (dim/expo)*np.log(smom) - np.log(const)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter values\n",
    "# These are used further down!\n",
    "\n",
    "# dimension\n",
    "mvals = np.array([1,2,3])\n",
    "\n",
    "# neighbours\n",
    "kvals = np.array([1,2,3])\n",
    "\n",
    "# exponent\n",
    "svals = np.array([0.5, 1.0, 1.5, 2.0, 2.5])\n",
    "\n",
    "# sample size\n",
    "Nmin = 10\n",
    "Nmax = 500\n",
    "Ninc = 10\n",
    "Nvals = np.arange(start=Nmin, stop=Nmax+1, step=Ninc)\n",
    "\n",
    "# repetitions\n",
    "nreps = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data \n",
    "def create_data(Nvals, mvals, svals, kvals, nreps):\n",
    "    \n",
    "    # init memory\n",
    "    datacube = np.zeros(shape=(nreps,len(Nvals),len(mvals), len(svals), len(svals), len(kvals)))\n",
    "\n",
    "    # info\n",
    "    import datetime\n",
    "    print(datetime.datetime.now())\n",
    "    # main loop \n",
    "    for rep in range(nreps):\n",
    "        \n",
    "        # progress bar\n",
    "        print('\\r' + 'x'*(rep+1) + '-'*(nreps-rep-1), end='')\n",
    "\n",
    "        # iterate over m-values\n",
    "        for midx, m in enumerate(mvals):\n",
    "\n",
    "            # iterate over sR-values (reality)\n",
    "            for sRidx, sR in enumerate(svals):\n",
    "\n",
    "                # create sample\n",
    "                pts = create_points_GG(Nmax, dim=m, expo=sR)\n",
    "\n",
    "                # iterate over subsamples\n",
    "                for Nidx, N in enumerate(Nvals):\n",
    "\n",
    "                    # iterate over sH-values (hypothesised)\n",
    "                    for sHidx, sH in enumerate(svals):\n",
    "\n",
    "                        datacube[rep,Nidx,midx,sRidx,sHidx:] = compute_statistics(pts[:N], expo=sH, nnmax=len(kvals))\n",
    "\n",
    "    print('Ended at:   {}'.format(datetime.datetime.now()))\n",
    "    return(datacube)\n",
    "\n",
    "# check\n",
    "if input(\"Generate data: are you sure? (y/n)\") == \"y\":\n",
    "    data  = create_data(Nvals, mvals, svals, kvals, nreps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "np.save('datacube1.npy', data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data2 = np.load('datacube1.npy')\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot separately with errorbars (k fixed)\n",
    "kval = 1\n",
    "kidx = np.where(kvals==kval)[0][0]\n",
    "width = 12\n",
    "fig, axes = plt.subplots(nrows=len(svals), ncols=len(mvals), sharex=True, sharey=True, figsize=(width,1.5*width))\n",
    "for sidx, sval in enumerate(svals):\n",
    "    for midx, mval in enumerate(mvals):\n",
    "        ax = axes[sidx,midx]\n",
    "        ax.axhline(y=0, linewidth=1, color='k')\n",
    "        desc = st.describe(data[:,:,midx,sidx,sidx,kidx])\n",
    "        ax.errorbar(x=Nvals, y=desc.mean, yerr=np.sqrt(desc.variance)/np.sqrt(nreps), capsize=5, errorevery=5)\n",
    "        ax.set_title('m={}, s={}, k={}'.format(mval,sval,kval));\n",
    "        if sidx == len(svals)-1: ax.set_xlabel('$N$', fontsize=12)\n",
    "        if midx == 0: ax.set_ylabel('$T_{N,k}(m,s)$', fontsize=16)\n",
    "        ax.set_xlim([Nmin,Nmax])        \n",
    "        ax.set_ylim([-0.05,0.05]) # tweak        \n",
    "        ax.grid(1);    \n",
    "fig.tight_layout()\n",
    "plt.savefig('consistency-k={}.png'.format(kval))\n",
    "plt.show();    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
